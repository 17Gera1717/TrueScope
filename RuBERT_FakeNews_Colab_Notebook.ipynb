{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ –û–±—É—á–µ–Ω–∏–µ RuBERT –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–µ–π–∫–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π\n",
    "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å DeepPavlov/rubert-base-cased –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–µ–π–∫–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ Telegram-–±–æ—Ç–µ –∏–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º –ø—Ä–æ–µ–∫—Ç–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch scikit-learn pandas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "df = pd.read_csv(\"Dataset_With_Core_Fake_Claim_Formatted.csv\")\n",
    "df['text'] = df.apply(lambda row: row['CORE_FAKE_CLAIM'] if row['TYPE'] == 'fake_pair' else str(row['REAL_TEXT']).strip(), axis=1)\n",
    "df['label'] = df['TYPE'].apply(lambda x: 1 if x == 'fake_pair' else 0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "model_name = \"DeepPavlov/rubert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(self.texts[idx], truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors=\"pt\")\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_dataset = NewsDataset(X_train, y_train, tokenizer)\n",
    "val_dataset = NewsDataset(X_val, y_val, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=64fd904f6b044c2d9204c253b7853705\n",
      "2025-04-22 04:46:04,030 - clearml.Repository Detection - WARNING - Could not read Jupyter Notebook: No module named 'nbconvert'\n",
      "2025-04-22 04:46:04,031 - clearml.Repository Detection - WARNING - Please install nbconvert using \"pip install nbconvert\"\n",
      "2025-04-22 04:46:04,036 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: http://34.90.169.210:8080/projects/3dd09fb90a3342f2b98e9671493f8798/experiments/64fd904f6b044c2d9204c253b7853705/output/log\n",
      "2025-04-22 04:46:04,687 - clearml.Task - WARNING - Parameters must be of builtin type (Transformers/accelerator_config[AcceleratorConfig])\n",
      "CLEARML-SERVER new package available: UPGRADE to v2.0.0 is recommended!\n",
      "Release Notes:\n",
      "### Breaking Changes\n",
      "\n",
      "MongoDB major version was upgraded from v5.x to 6.x.\n",
      "Please note that if your current ClearML Server version is smaller than v1.17 (where MongoDB v5.x was first used), you'll need to first upgrade to ClearML Server v1.17.\n",
      "#### Upgrading to ClearML Server v1.17 from a previous version\n",
      "- If using docker-compose,  use the following docker-compose files:\n",
      "  * [docker-compose file](https://github.com/allegroai/clearml-server/blob/2976ce69cc91550a3614996e8a8d8cd799af2efd/upgrade/1_17_to_2_0/docker-compose.yml)\n",
      "  * [docker-compose file foe Windows](https://github.com/allegroai/clearml-server/blob/2976ce69cc91550a3614996e8a8d8cd799af2efd/upgrade/1_17_to_2_0/docker-compose-win10.yml)\n",
      "\n",
      "### New Features\n",
      "\n",
      "- New look and feel: Full light/dark themes ([clearml #1297](https://github.com/allegroai/clearml/issues/1297))\n",
      "- New UI task creation options\n",
      "  - Support bash as well as python scripts\n",
      "  - Support file upload\n",
      "- New UI setting for configuring cloud storage credentials with which ClearML can clean up cloud storage artifacts on task deletion. \n",
      "- Add UI scalar plots presentation of plots in sections grouped by metrics.\n",
      "- Add UI Batch export plot embed codes for all metric plots in a single click.\n",
      "- Add UI pipeline presentation of steps grouped into stages\n",
      "\n",
      "### Bug Fixes\n",
      "- Fix UI Model Endpoint's Number of Requests plot sometimes displays incorrect data\n",
      "- Fix UI datasets page does not filter according to project when dataset is running \n",
      "- Fix UI task scalar legend does not change colors when smoothing is enabled \n",
      "- Fix queue list in UI Workers and Queues page does not alphabetically sort by queue display name \n",
      "- Fix queue display name is not searchable in UI Task Creation modal's queue field\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [92/92 03:32, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.116076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.101400</td>\n",
       "      <td>0.344147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.020840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.125334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-22 04:46:28,100 - clearml.storage - INFO - Uploading: 2035.59MB to /tmp/model_package.otw7dhii.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            61% | 1235.00/2035.59 MB [00:45<00:39, 20.05MB/s]: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-22 04:47:13,725 - clearml.Task - INFO - Waiting for previous model to upload (2 pending, http://34.90.169.210:8081/HuggingFace Transformers/Trainer.64fd904f6b044c2d9204c253b7853705/models/checkpoint-69.zip)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ 100% | 2035.00/2035.59 MB [01:11<00:00, 94.76MB/s]: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-22 04:47:43,741 - clearml.Task - INFO - Waiting for previous model to upload (2 pending, http://34.90.169.210:8081/HuggingFace Transformers/Trainer.64fd904f6b044c2d9204c253b7853705/models/checkpoint-69.zip)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ 100% | 2035.59/2035.59 MB [01:24<00:00, 24.06MB/s]: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-22 04:47:52,716 - clearml.Task - INFO - Completed model upload to http://34.90.169.210:8081/HuggingFace%20Transformers/Trainer.64fd904f6b044c2d9204c253b7853705/models/checkpoint-23.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-22 04:47:53,456 - clearml.storage - INFO - Uploading: 2035.59MB to /tmp/model_package.k51l4wlj.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ 100% | 2035.59/2035.59 MB [00:27<00:00, 74.69MB/s]: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-22 04:48:20,714 - clearml.Task - INFO - Completed model upload to http://34.90.169.210:8081/HuggingFace%20Transformers/Trainer.64fd904f6b044c2d9204c253b7853705/models/checkpoint-46.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-22 04:48:21,523 - clearml.storage - INFO - Uploading: 2035.60MB to /tmp/model_package.2f6zzzvm.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  99% | 2025.00/2035.6 MB [00:36<00:00, 117.49MB/s]: /usr/local/lib/python3.10/dist-packages/tqdm/std.py:636: TqdmWarning: clamping frac to range [0, 1]\n",
      "  full_bar = Bar(frac,\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100% | 2035.60/2035.6 MB [00:41<00:00, 49.20MB/s]: \n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100% | 2035.60/2035.6 MB [00:25<00:00, 80.72MB/s]: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=92, training_loss=0.16159479430390764, metrics={'train_runtime': 153.7072, 'train_samples_per_second': 4.658, 'train_steps_per_second': 0.599, 'total_flos': 94193757818880.0, 'train_loss': 0.16159479430390764, 'epoch': 4.0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –æ–±—É—á–µ–Ω–∏–µ\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./rubert_fakenews\",\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\"\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994554f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(predictions, labels):\n",
    "    correct = (predictions == labels).sum().item()\n",
    "    total = len(labels)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "predictions = trainer.predict(val_dataset)\n",
    "preds = predictions.predictions.argmax(-1)\n",
    "labels = predictions.label_ids\n",
    "accuracy = calculate_accuracy(preds, labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('rubert_fakenews20/tokenizer_config.json',\n",
       " 'rubert_fakenews20/special_tokens_map.json',\n",
       " 'rubert_fakenews20/vocab.txt',\n",
       " 'rubert_fakenews20/added_tokens.json',\n",
       " 'rubert_fakenews20/tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å\n",
    "model.save_pretrained(\"rubert_fakenews20\")\n",
    "tokenizer.save_pretrained(\"rubert_fakenews20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e94de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Claculate gpu usage of the model in mb\n",
    "import torch\n",
    "\n",
    "def get_gpu_memory_usage(model):\n",
    "    \"\"\"\n",
    "    Calculate the GPU memory usage of a PyTorch model in MB.\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_memory = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024 ** 2)\n",
    "        return gpu_memory\n",
    "    else:\n",
    "        return 0\n",
    "# Calculate the GPU memory usage of the model\n",
    "gpu_memory_usage = get_gpu_memory_usage(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe5ceed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678.4628982543945"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda9005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
